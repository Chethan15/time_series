{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import os,sys,time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"4200_C005_2019_03_03.tsv\",sep = \",\", names = (\"kunag\",\"matnr\",\"date\",\"quantity\",\"price\"),header = None)\n",
    "data = data[data['quantity']>=0]\n",
    "df = data.copy()\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##n_series to find the individual series for a kunag,matnr combination\n",
    "def n_series(input_df,kunag,matnr):\n",
    "    #removing the negative value rows\n",
    "    input_df = input_df[input_df[\"quantity\"] >=0]    \n",
    "    df = input_df.copy()\n",
    "    \n",
    "    #finding a single customer(kunag),material(matnr) combination on the basis of input provided\n",
    "    n_df1 = df[(df[\"kunag\"] == kunag) & (df[\"matnr\"] == matnr)]\n",
    "    \n",
    "    #parsing the date column in a datetime format\n",
    "    n_df1.date = n_df1.date.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))\n",
    "    #sort date start to end\n",
    "    n_df1 = n_df1.sort_values('date')\n",
    "    n_df1.set_index('date',inplace=True)\n",
    "    \n",
    "    #sampling the data on weekly basis (index is set to date first in the above step to do weekly sampling\n",
    "    weekly_resampled_data = n_df1.quantity.resample('W').sum() \n",
    "    weekly_resampled_data = weekly_resampled_data.replace(np.nan, 0)\n",
    "    individual_series = weekly_resampled_data.to_frame() \n",
    "\n",
    "    individual_series[\"external3\"] = individual_series[\"quantity\"].rolling(3).sum().iloc[::]\n",
    "    individual_series['external3'] = individual_series['external3'].shift(1)\n",
    "    individual_series[\"external3\"].fillna(0,inplace = True)\n",
    "    \n",
    "    individual_series[\"external6\"] = individual_series[\"quantity\"].rolling(6).sum().iloc[::]\n",
    "    individual_series['external6'] = individual_series['external6'].shift(1)\n",
    "    individual_series[\"external6\"].fillna(0,inplace = True)\n",
    "    \n",
    "    #resetting index so that date can be used as column\n",
    "    individual_series = individual_series.reset_index()\n",
    "    return individual_series\n",
    "\n",
    "\n",
    "#splitting the individual series basesd on the number of weeks (i, is for dyanamic point forecasts)\n",
    "def train_test_split(input_df,kunag,matnr,i):\n",
    "    data= n_series(input_df,kunag,matnr)\n",
    "    train = data.iloc[2:-i]    \n",
    "    test = data.iloc[-i:]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sarima WITHOUT external regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima(input_df, kunag,matnr,n,p,d,q):\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split(df,kunag,matnr,n)[1]\n",
    "    y_hat_avg = test1.copy()\n",
    "    start_date = str(test1[\"date\"][:1])\n",
    "    end_date = str(test1[\"date\"][-1:])\n",
    "    order = (p, d,q)\n",
    "    for i in range(n,0,-1):\n",
    "        train,test = train_test_split(df,kunag,matnr,i)\n",
    "        dd= np.asarray(train[\"quantity\"])\n",
    "        \n",
    "        ## WITHOUT external regressor\n",
    "        fit1 = sm.tsa.statespace.SARIMAX(train[\"quantity\"],order=order,enforce_stationarity = False, enforce_invertibility = False,trend = \"n\").fit()    \n",
    "        \n",
    "        pred = fit1.predict(1)\n",
    "        lst.append(pred.iloc[-1])\n",
    "\n",
    "    pd.DataFrame(lst)\n",
    "    y_hat_avg['pred_column']=lst\n",
    "\n",
    "    rms = sqrt(mean_squared_error(test1.quantity, y_hat_avg.pred_column))\n",
    "    mae = mean_absolute_error(test1.quantity, y_hat_avg.pred_column)\n",
    "    return y_hat_avg,rms,mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sarima WITH external regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima_er(input_df, kunag,matnr,n,p,d,q):\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split(df,kunag,matnr,n)[1]\n",
    "    y_hat_avg = test1.copy()\n",
    "    start_date = str(test1[\"date\"][:1])\n",
    "    end_date = str(test1[\"date\"][-1:])\n",
    "    order = (p, d,q)\n",
    "    for i in range(n,0,-1):\n",
    "        train,test = train_test_split(df,kunag,matnr,i)\n",
    "        dd= np.asarray(train[\"quantity\"])\n",
    "\n",
    "        ## with external regressor\n",
    "        model1 = sm.tsa.statespace.SARIMAX(train[\"quantity\"], exog = sm.add_constant(train[\"external\"]),order=order,enforce_stationarity = False, enforce_invertibility = False,trend = \"n\")    \n",
    "        fit1 = model1.fit()\n",
    "        exog_pred = [[1, train[\"quantity\"].iloc[-7:].sum()]]\n",
    "        pred = fit1.forecast(1, exog=exog_pred)\n",
    "#         pred = fit1.predict(1)\n",
    "        lst.append(pred.iloc[-1])\n",
    "\n",
    "    pd.DataFrame(lst)\n",
    "    y_hat_avg['pred_column']=lst\n",
    "    rms = sqrt(mean_squared_error(test1.quantity, y_hat_avg.pred_column))\n",
    "    mae = mean_absolute_error(test1.quantity, y_hat_avg.pred_column)\n",
    "    return y_hat_avg,rms,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima_er1(input_df, kunag,matnr,n,p,d,q):\n",
    "    i = 0\n",
    "    lst1 = []\n",
    "    lst2 = []\n",
    "    test1 = train_test_split(df,kunag,matnr,n)[1]\n",
    "    y_hat_avg = test1.copy()\n",
    "    start_date = str(test1[\"date\"][:1])\n",
    "    end_date = str(test1[\"date\"][-1:])\n",
    "    order = (p, d,q)\n",
    "    for i in range(n,0,-1):\n",
    "        train,test = train_test_split(df,kunag,matnr,i)\n",
    "        dd= np.asarray(train[\"quantity\"])\n",
    "\n",
    "        ## with external regressor\n",
    "        model1 = sm.tsa.statespace.SARIMAX(train[\"quantity\"], exog = sm.add_constant(train[\"external3\"]),order=order,enforce_stationarity = False, enforce_invertibility = False,trend = \"n\")    \n",
    "        model2 = sm.tsa.statespace.SARIMAX(train[\"quantity\"], exog = sm.add_constant(train[\"external6\"]),order=order,enforce_stationarity = False, enforce_invertibility = False,trend = \"n\")    \n",
    "\n",
    "        fit1 = model1.fit()\n",
    "        fit2 = model2.fit()\n",
    "\n",
    "        exog_pred1 = [[1, train[\"quantity\"].iloc[-3:].sum()]]\n",
    "        exog_pred2 = [[1, train[\"quantity\"].iloc[-6:].sum()]]\n",
    "\n",
    "        \n",
    "        pred1 = fit1.forecast(1, exog=exog_pred1)\n",
    "        pred2 = fit2.forecast(1, exog=exog_pred2)\n",
    "\n",
    "        lst1.append(pred1.iloc[-1])\n",
    "        lst2.append(pred2.iloc[-1])\n",
    "        \n",
    "        \n",
    "    pd.DataFrame(lst1)\n",
    "    pd.DataFrame(lst2)\n",
    "\n",
    "    y_hat_avg['pred_column1']=lst1      \n",
    "    y_hat_avg['pred_column2']=lst2\n",
    "\n",
    "#     rms = sqrt(mean_squared_error(test1.quantity, y_hat_avg.pred_column))\n",
    "#     mae = mean_absolute_error(test1.quantity, y_hat_avg.pred_column)\n",
    "    return y_hat_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data.copy()\n",
    "# sarima_er1(df, 500056565,100278,16,0,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Comparisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df,kunag,matnr,n):\n",
    "        p,d,q = 0,1,1\n",
    "        train,test1 = train_test_split(df,kunag,matnr,n)\n",
    "\n",
    "        output1,rms1,mae1 = sarima(df,kunag,matnr,n,p,d,q)\n",
    "#         output2,rms2,mae2 = sarima_er(df,kunag,matnr,n,p,d,q)\n",
    "        \n",
    "       ##combined freq 3 and 6 \n",
    "        output = sarima_er1(df,kunag,matnr,n,p,d,q)\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(18,10))\n",
    "        plt.plot(train.set_index(\"date\")['quantity'], label='Train',marker = '.')\n",
    "        plt.plot(test1.set_index(\"date\")['quantity'], label='Test',marker = '.')\n",
    "        plt.plot(output1.set_index(\"date\")['pred_column'], label='arima' ,marker = '.')\n",
    "#         plt.plot(output2.set_index(\"date\")['pred_column'], label='arima_x' ,marker = '.')  \n",
    "        \n",
    "        ##plot for combined freq 3 and 6 \n",
    "        plt.plot(output.set_index(\"date\")['pred_column1'], label='arima_3' ,marker = '.')\n",
    "        plt.plot(output.set_index(\"date\")['pred_column2'], label='arima_6' ,marker = '.',color = \"blue\")  \n",
    "        \n",
    "        plt.legend(loc='best')\n",
    "        plt.title(\"Arima_3_6_Comparision\")\n",
    "        plt.savefig(folder +\"/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n",
    "#         plt.show()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# folder = 'model_graphs/'+\"SARIMAX_3_7\"\n",
    "# if not os.path.exists(folder):\n",
    "#         os.makedirs(folder)\n",
    "# df = data.copy()\n",
    "# bucket = pd.read_csv(\"bucket.csv\")\n",
    "\n",
    "# main_df = pd.DataFrame(columns = {\"kunag\",\"matnr\",\"mae_arima\",\"mae_sarimax\"})\n",
    "# cnt = 1\n",
    "# n = 16\n",
    "# for i in range (1,2):\n",
    "#             start = time.time()\n",
    "#             kunag = int(bucket[\"kunag\"].iloc[i])\n",
    "#             matnr = int(bucket[\"matnr\"].iloc[i])\n",
    "#             index = str(kunag) +\"_\"+ str(matnr)\n",
    "#             print(\"count\",cnt)\n",
    "#             print(\"index : \",index)\n",
    "            \n",
    "#             #PLOT_COMPARISION\n",
    "#             mae1,mae2 = plot(df,kunag,matnr,n)\n",
    "\n",
    "#             result_df = pd.DataFrame(OrderedDict({\"kunag\" : [kunag],\"matnr\" : [matnr],\n",
    "#                        \"mae_arima\" : [round(mae1,3)],\n",
    "#                        \"mae_sarimax\" : [round(mae2,3)]}))\n",
    "\n",
    "#             print(result_df)\n",
    "#             main_df = main_df.append(result_df, ignore_index = True) \n",
    "#             export_csv = main_df.to_csv (r'model_graphs/SARIMAX_F16/results/arima_x_comp().csv',sep = \",\", index = None, header=True)\n",
    "#             end = time.time()\n",
    "#             cnt+=1\n",
    "#             print(\"Time Taken : \",end - start)  \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For combined 3 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'model_graphs/'+\"SARIMAX_3_6\"\n",
    "if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "df = data.copy()\n",
    "bucket = pd.read_csv(\"bucket.csv\")\n",
    "\n",
    "# main_df = pd.DataFrame(columns = {\"kunag\",\"matnr\",\"mae_arima\",\"mae_sarimax\"})\n",
    "cnt = 1\n",
    "n = 16\n",
    "for i in range (201,501):\n",
    "            start = time.time()\n",
    "            kunag = int(bucket[\"kunag\"].iloc[i])\n",
    "            matnr = int(bucket[\"matnr\"].iloc[i])\n",
    "            index = str(kunag) +\"_\"+ str(matnr)\n",
    "            print(\"count\",cnt)\n",
    "            print(\"index : \",index)\n",
    "            \n",
    "            #PLOT_COMPARISION\n",
    "            output =  plot(df,kunag,matnr,n)\n",
    "\n",
    "#             result_df = pd.DataFrame(OrderedDict({\"kunag\" : [kunag],\"matnr\" : [matnr],\n",
    "#                        \"mae_arima\" : [round(mae1,3)],\n",
    "#                        \"mae_sarimax\" : [round(mae2,3)]}))\n",
    "\n",
    "#             print(result_df)\n",
    "#             main_df = main_df.append(result_df, ignore_index = True) \n",
    "#             export_csv = main_df.to_csv (r'model_graphs/SARIMAX_F16/results/arima_x_comp().csv',sep = \",\", index = None, header=True)\n",
    "            end = time.time()\n",
    "            cnt+=1\n",
    "            print(\"Time Taken : \",end - start)  \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Csv Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls model_graphs/SARIMAX_F3/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"model_graphs/SARIMAX_F3/results/arima_x_comp(0,100).csv\",sep = \",\")\n",
    "df2 = pd.read_csv(\"model_graphs/SARIMAX_F3/results/arima_x_comp(100,200).csv\", sep = \",\")\n",
    "df3 = pd.read_csv(\"model_graphs/SARIMAX_F3/results/arima_x_comp(200,500).csv\", sep = \",\")\n",
    "df4 = pd.read_csv(\"model_graphs/SARIMAX_F3/results/arima_x_comp(500,1000).csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "print(df4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df3, df2,df4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum = df.idxmin(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "\n",
    "for i in range(0,len(minimum)):\n",
    "    if(minimum[i]==\"mae_arima\"):\n",
    "        a+=1\n",
    "    elif(minimum[i]==\"mae_sarimax\"):\n",
    "        b+=1\n",
    "\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis = 0, skipna = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima__ = 530\n",
    "arima_x3__ = 470\n",
    "mae_arima     = 8.218440e+02\n",
    "mae_sarimax3   = 8.143150e+02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##n_series to find the individual series for a kunag,matnr combination\n",
    "def n_series1(input_df,kunag,matnr):\n",
    "    #removing the negative value rows\n",
    "    input_df = input_df[input_df[\"quantity\"] >=0]    \n",
    "    df = input_df.copy()\n",
    "    \n",
    "    #finding a single customer(kunag),material(matnr) combination on the basis of input provided\n",
    "    n_df1 = df[(df[\"kunag\"] == kunag) & (df[\"matnr\"] == matnr)]\n",
    "    \n",
    "    #parsing the date column in a datetime format\n",
    "    n_df1.date = n_df1.date.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))\n",
    "    #sort date start to end\n",
    "    n_df1 = n_df1.sort_values('date')\n",
    "    n_df1.set_index('date',inplace=True)\n",
    "    \n",
    "    #sampling the data on weekly basis (index is set to date first in the above step to do weekly sampling\n",
    "    weekly_resampled_data = n_df1.quantity.resample('W').sum() \n",
    "    weekly_resampled_data = weekly_resampled_data.replace(np.nan, 0)\n",
    "    individual_series = weekly_resampled_data.to_frame() \n",
    "\n",
    "    individual_series[\"external1\"] = individual_series[\"quantity\"].rolling(1).sum().iloc[::]\n",
    "    individual_series['external1'] = individual_series['external1'].shift(1)\n",
    "    individual_series[\"external1\"].fillna(0,inplace = True)\n",
    "    \n",
    "    individual_series[\"external2\"] = individual_series[\"quantity\"].rolling(2).sum().iloc[::]\n",
    "    individual_series['external2'] = individual_series['external2'].shift(1)\n",
    "    individual_series[\"external2\"].fillna(0,inplace = True)\n",
    "    \n",
    "    individual_series[\"external3\"] = individual_series[\"quantity\"].rolling(3).sum().iloc[::]\n",
    "    individual_series['external3'] = individual_series['external3'].shift(1)\n",
    "    individual_series[\"external3\"].fillna(0,inplace = True)\n",
    "    \n",
    "    #resetting index so that date can be used as column\n",
    "    individual_series = individual_series.reset_index()\n",
    "    return individual_series\n",
    "\n",
    "\n",
    "#splitting the individual series basesd on the number of weeks (i, is for dyanamic point forecasts)\n",
    "def train_test_split1(input_df,kunag,matnr,i):\n",
    "    data= n_series1(input_df,kunag,matnr)\n",
    "    train = data.iloc[3:-i]    \n",
    "    test = data.iloc[-i:]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split1(df,500056565,100278,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarimax_multix(input_df, kunag,matnr,n,p,d,q):\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split1(df,kunag,matnr,n)[1]\n",
    "    y_hat_avg = test1.copy()\n",
    "    start_date = str(test1[\"date\"][:1])\n",
    "    end_date = str(test1[\"date\"][-1:])\n",
    "    order = (p, d,q)\n",
    "    for i in range(n,0,-1):\n",
    "        train,test = train_test_split1(df,kunag,matnr,i)\n",
    "        dd= np.asarray(train[\"quantity\"])\n",
    "\n",
    "        ## with external regressor\n",
    "        model1 = sm.tsa.statespace.SARIMAX(train[\"quantity\"], exog = sm.add_constant(train[['external1','external2','external3']]),order=order,enforce_stationarity = False, enforce_invertibility = False,trend = \"n\")    \n",
    "        fit1 = model1.fit()\n",
    "        x1 = train[\"quantity\"].iloc[-1:].sum()\n",
    "        x2 = train[\"quantity\"].iloc[-2:].sum()\n",
    "        x3 = train[\"quantity\"].iloc[-3:].sum()\n",
    "    \n",
    "\n",
    "#         exog_pred = [[1, train[\"quantity\"].iloc[-7:].sum()]]\n",
    "        exog_pred = [[1, x1,x2,x3]]\n",
    "\n",
    "        pred = fit1.forecast(1, exog=exog_pred)\n",
    "#         pred = fit1.predict(1)\n",
    "        lst.append(pred.iloc[-1])\n",
    "\n",
    "    pd.DataFrame(lst)\n",
    "    y_hat_avg['pred_column']=lst\n",
    "    rms = sqrt(mean_squared_error(test1.quantity, y_hat_avg.pred_column))\n",
    "    mae = mean_absolute_error(test1.quantity, y_hat_avg.pred_column)\n",
    "    return y_hat_avg,rms,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df,kunag,matnr,n):\n",
    "        p,d,q = 0,1,1\n",
    "        train,test1 = train_test_split(df,kunag,matnr,n)\n",
    "\n",
    "        output1,rms1,mae1 = sarima(df,kunag,matnr,n,p,d,q)\n",
    "#         output2,rms2,mae2 = sarima_er(df,kunag,matnr,n,p,d,q)\n",
    "        \n",
    "       ##combined freq 3 and 6 \n",
    "        output,rms,mae = sarimax_multix(df,kunag,matnr,n,p,d,q)\n",
    "\n",
    "        \n",
    "        plt.figure(figsize=(18,10))\n",
    "        plt.plot(train.set_index(\"date\")['quantity'], label='Train',marker = '.')\n",
    "        plt.plot(test1.set_index(\"date\")['quantity'], label='Test',marker = '.')\n",
    "        plt.plot(output1.set_index(\"date\")['pred_column'], label='arima' ,marker = '.')\n",
    "#         plt.plot(output2.set_index(\"date\")['pred_column'], label='arima_x' ,marker = '.')  \n",
    "        \n",
    "        ##plot for combined freq 3 and 6 \n",
    "        plt.plot(output.set_index(\"date\")['pred_column'], label='arimax_(1,2,3)' ,marker = '.')\n",
    "#         plt.plot(output.set_index(\"date\")['pred_column2'], label='arima_6' ,marker = '.',color = \"blue\")  \n",
    "        \n",
    "        plt.legend(loc='best')\n",
    "        plt.title(\"Arima_3_6_Comparision\")\n",
    "        plt.savefig(folder +\"/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n",
    "#         plt.show()\n",
    "        return mae1,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'model_graphs/'+\"SARIMAX_123\"\n",
    "if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "bucket = pd.read_csv(\"bucket.csv\")\n",
    "\n",
    "main_df = pd.DataFrame(columns = {\"kunag\",\"matnr\",\"mae_arima\",\"mae_sarimax123\"})\n",
    "cnt = 1\n",
    "n = 16\n",
    "for i in range (601,1001):\n",
    "            start = time.time()\n",
    "            kunag = int(bucket[\"kunag\"].iloc[i])\n",
    "            matnr = int(bucket[\"matnr\"].iloc[i])\n",
    "            index = str(kunag) +\"_\"+ str(matnr)\n",
    "            print(\"count\",cnt)\n",
    "            print(\"index : \",index)\n",
    "            \n",
    "            #PLOT_COMPARISION\n",
    "            mae1,mae = plot(df,kunag,matnr,n)\n",
    "\n",
    "            result_df = pd.DataFrame(OrderedDict({\"kunag\" : [kunag],\"matnr\" : [matnr],\n",
    "                       \"mae_arima\" : [round(mae1,3)],\n",
    "                       \"mae_sarimax123\" : [round(mae,3)]}))\n",
    "\n",
    "            print(result_df)\n",
    "            main_df = main_df.append(result_df, ignore_index = True) \n",
    "            export_csv = main_df.to_csv (r'model_graphs/SARIMAX_123/results/arima_x_comp(600-400).csv',sep = \",\", index = None, header=True)\n",
    "            end = time.time()\n",
    "            cnt+=1\n",
    "            print(\"Time Taken : \",end - start)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
