{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import dateutil.parser\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "import statsmodels.api as sm\n",
    "# from preprocess import train_test_split\n",
    "# from preprocess import n_series\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/rahul/Downloads/bharat/time_series1/4200_C005_2019_03_03.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, sep=',', header=None)\n",
    "df.columns = [\"kunag\", \"matnr\", \"date\", \"quantity\",\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_test_split(input_df,kunag,matnr,i):\n",
    "#     data= n_series(input_df,kunag,matnr)\n",
    "#     train = data[0:-i+1]    \n",
    "#     test = data[-i-1:]\n",
    "#     train = train.astype('float32')\n",
    "#     test = test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm1(df,500056565, 100278,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "def n_series(input_df,kunag,matnr):\n",
    "    input_df = input_df[input_df[\"quantity\"] >=0]    \n",
    "    df = input_df.copy()\n",
    "    n_df1 = df[(df[\"kunag\"] == kunag) & (df[\"matnr\"] == matnr)]\n",
    "    n_df1.date = n_df1.date.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))\n",
    "    n_df1 = n_df1.sort_values('date')\n",
    "    n_df1.set_index('date',inplace=True)\n",
    "    weekly_resampled_data = n_df1.quantity.resample('W').sum() \n",
    "    weekly_resampled_data = weekly_resampled_data.replace(np.nan, 0)\n",
    "    individual_series = weekly_resampled_data.to_frame()\n",
    "    dataset = individual_series.values\n",
    "    # normalize the dataset\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     dataset = scaler.fit_transform(dataset)\n",
    "#     individual_series = individual_series.reset_index()\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_test_split(input_df,kunag,matnr,i):\n",
    "    data= n_series(input_df,kunag,matnr)\n",
    "    train = data[0:-i]    \n",
    "    test = data[-i:-1]\n",
    "    train = train.astype('float32')\n",
    "    test = test.astype('float32')\n",
    "\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     train = scaler.fit_transform(train)\n",
    "#     test = scaler.fit_transform(test)\n",
    "    return train,test\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_series1(input_df,kunag,matnr):\n",
    "    input_df = input_df[input_df[\"quantity\"] >=0]    \n",
    "    df = input_df.copy()\n",
    "    n_df1 = df[(df[\"kunag\"] == kunag) & (df[\"matnr\"] == matnr)]\n",
    "    n_df1.date = n_df1.date.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))\n",
    "    n_df1 = n_df1.sort_values('date')\n",
    "    n_df1.set_index('date',inplace=True)\n",
    "    weekly_resampled_data = n_df1.quantity.resample('W').sum() \n",
    "    weekly_resampled_data = weekly_resampled_data.replace(np.nan, 0)\n",
    "    individual_series = weekly_resampled_data.to_frame()\n",
    "#     dataset = individual_series.values\n",
    "#     main_series = individual_series.reset_index()\n",
    "    return individual_series\n",
    "\n",
    "def n_series2(input_df,kunag,matnr):\n",
    "    input_df = input_df[input_df[\"quantity\"] >=0]    \n",
    "    df = input_df.copy()\n",
    "    n_df1 = df[(df[\"kunag\"] == kunag) & (df[\"matnr\"] == matnr)]\n",
    "    n_df1.date = n_df1.date.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))\n",
    "    n_df1 = n_df1.sort_values('date')\n",
    "    n_df1.set_index('date',inplace=True)\n",
    "    weekly_resampled_data = n_df1.quantity.resample('W').sum() \n",
    "    weekly_resampled_data = weekly_resampled_data.replace(np.nan, 0)\n",
    "    individual_series = weekly_resampled_data.to_frame()\n",
    "#     dataset = individual_series.values\n",
    "    main_series = individual_series.reset_index()\n",
    "    return main_series\n",
    "\n",
    "\n",
    "def train_test_split1(input_df,kunag,matnr,i):\n",
    "    data= n_series(input_df,kunag,matnr)\n",
    "    train = data[0:-i+4]    \n",
    "    test = data[-i-4:]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# LSTM for international airline passengers problem with regression framing\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = n_series1(df,500056565, 100278)\n",
    "print(dataframe.head())\n",
    "# dataframe.set_index('date',inplace=True)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# split into train and test sets\n",
    "# train_size = int(len(dataset) * 0.67)\n",
    "# test_size = len(dataset) - train_size\n",
    "# train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "train,test = train_test_split1(df,500056565, 100278,16)\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.fit_transform(test)\n",
    "\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=10, batch_size=1, verbose=2)\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "print(\"trainPredict :\",len(trainPredict))\n",
    "print(\"dataset :\", len(dataset))\n",
    "print(\"testPredict :\", len(testPredict))\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)-6:len(dataset), :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "# plt.plot(scaler.inverse_transform(test))\n",
    "# plt.plot(dataframe.set_index(\"date\")['quantity'])\n",
    "\n",
    "# plt.plot(trainPredictPlot, marker=\".\")\n",
    "plt.plot(testPredictPlot, marker=\"o\",color = \"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ses(input_df, kunag,matnr,n):\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split(df,kunag,matnr,n)[1]\n",
    "    y_hat_avg = test1.copy()\n",
    "    for i in range(n,1,-1):\n",
    "        numpy.random.seed(7)\n",
    "    # load the dataset\n",
    "        dataframe = n_series1(df,500056565, 100278)\n",
    "        print(dataframe.head())\n",
    "\n",
    "        dataset = dataframe.values\n",
    "        dataset = dataset.astype('float32')\n",
    "        # normalize the dataset\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "        # split into train and test sets\n",
    "        # train_size = int(len(dataset) * 0.67)\n",
    "        # test_size = len(dataset) - train_size\n",
    "        # train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "        train,test = train_test_split1(df,500056565, 100278,n)\n",
    "        train = scaler.fit_transform(train)\n",
    "        test = scaler.fit_transform(test)\n",
    "\n",
    "        # reshape into X=t and Y=t+1\n",
    "        look_back = 3\n",
    "        trainX, trainY = create_dataset(train, look_back)\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "        # reshape input to be [samples, time steps, features]\n",
    "        trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        # create and fit the LSTM network\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        model.fit(trainX, trainY, epochs=10, batch_size=1, verbose=2)\n",
    "        # make predictions\n",
    "        trainPredict = model.predict(trainX)\n",
    "        testPredict = model.predict(testX)\n",
    "        # invert predictions\n",
    "        trainPredict = scaler.inverse_transform(trainPredict)\n",
    "        trainY = scaler.inverse_transform([trainY])\n",
    "        testPredict = scaler.inverse_transform(testPredict)\n",
    "        testY = scaler.inverse_transform([testY])\n",
    "        lst.append(pred.iloc[0])\n",
    "\n",
    "    pd.DataFrame(lst)\n",
    "    y_hat_avg['pred_column']=lst\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot( train.set_index(\"date\")['quantity'], label='Train')\n",
    "    plt.plot(test.set_index(\"date\")['quantity'], label='Test')\n",
    "    plt.plot(y_hat_avg.set_index(\"date\")['pred_column'], label='SES')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"SES\")\n",
    "    plt.show()\n",
    "    rms = sqrt(mean_squared_error(test1.quantity, y_hat_avg.pred_column))\n",
    "    print(\"rms = \", rms)\n",
    "    del y_hat_avg['SES']\n",
    "    return y_hat_avg\n",
    "\n",
    "\n",
    "\n",
    "numpy.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = n_series1(df,500056565, 100278)\n",
    "print(dataframe.head())\n",
    "\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# split into train and test sets\n",
    "# train_size = int(len(dataset) * 0.67)\n",
    "# test_size = len(dataset) - train_size\n",
    "# train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "train,test = train_test_split1(df,500056565, 100278,16)\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.fit_transform(test)\n",
    "\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=10, batch_size=1, verbose=2)\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "print(\"trainPredict :\",len(trainPredict))\n",
    "print(\"dataset :\", len(dataset))\n",
    "print(\"testPredict :\", len(testPredict))\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)-6:len(dataset), :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "# plt.plot(scaler.inverse_transform(test))\n",
    "# plt.plot(dataframe.set_index(\"date\")['quantity'])\n",
    "\n",
    "# plt.plot(trainPredictPlot, marker=\".\")\n",
    "plt.plot(testPredictPlot, marker=\"o\",color = \"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lst(input_df, kunag,matnr,n):\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split(df,kunag,matnr,n)[1]\n",
    "    y_hat_avg = test1.copy()\n",
    "    for i in range(n,3,-1):\n",
    "        numpy.random.seed(7)\n",
    "    # load the dataset\n",
    "        dataframe = n_series1(df,500056565, 100278)\n",
    "#         print(dataframe.head())\n",
    "\n",
    "        dataset = dataframe.values\n",
    "        dataset = dataset.astype('float32')\n",
    "        # normalize the dataset\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "        train,test = train_test_split1(df,500056565, 100278,i)\n",
    "        train = scaler.fit_transform(train)\n",
    "        test = scaler.fit_transform(test)\n",
    "\n",
    "        # reshape into X=t and Y=t+1\n",
    "        look_back = 3\n",
    "        trainX, trainY = create_dataset(train, look_back)\n",
    "        testX, testY = create_dataset(test, look_back)\n",
    "        # reshape input to be [samples, time steps, features]\n",
    "        trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "        testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        print(trainX.shape)\n",
    "        print(testX.shape)\n",
    "        # create and fit the LSTM network\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        model.fit(trainX, trainY, epochs=10, batch_size=1, verbose=2)\n",
    "        # make predictions\n",
    "        trainPredict = model.predict(trainX)\n",
    "        testPredict = model.predict(testX)\n",
    "        # invert predictions\n",
    "        trainPredict = scaler.inverse_transform(trainPredict)\n",
    "        trainY = scaler.inverse_transform([trainY])\n",
    "        testPredict = scaler.inverse_transform(testPredict)\n",
    "        testY = scaler.inverse_transform([testY])\n",
    "        print(testPredict.shape)\n",
    "        testPredict=  testPredict.tolist()\n",
    "        print(type(testPredict))\n",
    "        lst.append(testPredict[0])\n",
    "        print(testPredict[0])\n",
    "        print(\"lst :\" ,lst)\n",
    "#     pd.DataFrame(lst)\n",
    "#     y_hat_avg['pred_column']=lst\n",
    "#     plt.figure(figsize=(12,8))\n",
    "#     plt.plot( train.set_index(\"date\")['quantity'], label='Train')\n",
    "#     plt.plot(test.set_index(\"date\")['quantity'], label='Test')\n",
    "#     plt.plot(y_hat_avg.set_index(\"date\")['pred_column'], label='SES')\n",
    "#     plt.legend(loc='best')\n",
    "#     plt.title(\"SES\")\n",
    "#     plt.show()\n",
    "#     rms = sqrt(mean_squared_error(test1.quantity, y_hat_avg.pred_column))\n",
    "#     print(\"rms = \", rms)\n",
    "#     del y_hat_avg['SES']\n",
    "    return lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst(df,500056565, 100278,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 1, 3)\n",
      "(16, 1, 3)\n",
      "Epoch 1/10\n",
      " - 7s - loss: 0.0584\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0451\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0430\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0423\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0422\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0421\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0417\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0417\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0416\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0415\n",
      "(16, 1)\n",
      "<class 'list'>\n",
      "[0.727053165435791]\n",
      "lst : [[0.727053165435791]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 1, 3)\n",
      "(15, 1, 3)\n",
      "Epoch 1/10\n",
      " - 7s - loss: 0.0574\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0451\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0429\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0426\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0420\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0419\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0416\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0416\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0415\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0417\n",
      "(15, 1)\n",
      "<class 'list'>\n",
      "[0.656582236289978]\n",
      "lst : [[0.727053165435791], [0.656582236289978]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 1, 3)\n",
      "(14, 1, 3)\n",
      "Epoch 1/10\n",
      " - 7s - loss: 0.0570\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0449\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0425\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0423\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0420\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0417\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0420\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0415\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0413\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0411\n",
      "(14, 1)\n",
      "<class 'list'>\n",
      "[0.438305526971817]\n",
      "lst : [[0.727053165435791], [0.656582236289978], [0.438305526971817]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 1, 3)\n",
      "(13, 1, 3)\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.0584\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0453\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0426\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0420\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0417\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0416\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0414\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0413\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0411\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0410\n",
      "(13, 1)\n",
      "<class 'list'>\n",
      "[0.37979230284690857]\n",
      "lst : [[0.727053165435791], [0.656582236289978], [0.438305526971817], [0.37979230284690857]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 1, 3)\n",
      "(12, 1, 3)\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.0579\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0453\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0425\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0424\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0415\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0415\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0412\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0412\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0411\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0408\n",
      "(12, 1)\n",
      "<class 'list'>\n",
      "[0.48489850759506226]\n",
      "lst : [[0.727053165435791], [0.656582236289978], [0.438305526971817], [0.37979230284690857], [0.48489850759506226]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 1, 3)\n",
      "(11, 1, 3)\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.0557\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0441\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0424\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0417\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0415\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0413\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0411\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0409\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0408\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0407\n",
      "(11, 1)\n",
      "<class 'list'>\n",
      "[0.632003903388977]\n",
      "lst : [[0.727053165435791], [0.656582236289978], [0.438305526971817], [0.37979230284690857], [0.48489850759506226], [0.632003903388977]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 1, 3)\n",
      "(10, 1, 3)\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.0550\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0436\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0422\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0414\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0412\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0410\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0410\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0407\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0406\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0404\n",
      "(10, 1)\n",
      "<class 'list'>\n",
      "[0.40921130776405334]\n",
      "lst : [[0.727053165435791], [0.656582236289978], [0.438305526971817], [0.37979230284690857], [0.48489850759506226], [0.632003903388977], [0.40921130776405334]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 1, 3)\n",
      "(9, 1, 3)\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.0546\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0435\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0416\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0412\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0410\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0409\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0406\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0407\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0403\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0401\n",
      "(9, 1)\n",
      "<class 'list'>\n",
      "[0.40674108266830444]\n",
      "lst : [[0.727053165435791], [0.656582236289978], [0.438305526971817], [0.37979230284690857], [0.48489850759506226], [0.632003903388977], [0.40921130776405334], [0.40674108266830444]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 1, 3)\n",
      "(8, 1, 3)\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.0543\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0430\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0412\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0410\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0408\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0407\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0406\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0404\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0404\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0401\n",
      "(8, 1)\n",
      "<class 'list'>\n",
      "[0.4210386872291565]\n",
      "lst : [[0.727053165435791], [0.656582236289978], [0.438305526971817], [0.37979230284690857], [0.48489850759506226], [0.632003903388977], [0.40921130776405334], [0.40674108266830444], [0.4210386872291565]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1, 3)\n",
      "(7, 1, 3)\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.0537\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0428\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0412\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0409\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0405\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0405\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0401\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0401\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0399\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0399\n",
      "(7, 1)\n",
      "<class 'list'>\n",
      "[0.42171961069107056]\n",
      "lst : [[0.727053165435791], [0.656582236289978], [0.438305526971817], [0.37979230284690857], [0.48489850759506226], [0.632003903388977], [0.40921130776405334], [0.40674108266830444], [0.4210386872291565], [0.42171961069107056]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 1, 3)\n",
      "(6, 1, 3)\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.0536\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0428\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0412\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0409\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0406\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0404\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0401\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0399\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0398\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0397\n",
      "(6, 1)\n",
      "<class 'list'>\n",
      "[0.4004541039466858]\n",
      "lst : [[0.727053165435791], [0.656582236289978], [0.438305526971817], [0.37979230284690857], [0.48489850759506226], [0.632003903388977], [0.40921130776405334], [0.40674108266830444], [0.4210386872291565], [0.42171961069107056], [0.4004541039466858]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 1, 3)\n",
      "(5, 1, 3)\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.0534\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0428\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0410\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0408\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0405\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0404\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0401\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0400\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0399\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0396\n",
      "(5, 1)\n",
      "<class 'list'>\n",
      "[0.40133392810821533]\n",
      "lst : [[0.727053165435791], [0.656582236289978], [0.438305526971817], [0.37979230284690857], [0.48489850759506226], [0.632003903388977], [0.40921130776405334], [0.40674108266830444], [0.4210386872291565], [0.42171961069107056], [0.4004541039466858], [0.40133392810821533]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/home/rahul/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-efb2c1b7f738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500056565\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100278\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-038427665b52>\u001b[0m in \u001b[0;36mlst\u001b[0;34m(input_df, kunag, matnr, n)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500056565\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100278\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         X = check_array(X, copy=self.copy, warn_on_dtype=True,\n\u001b[0;32m--> 334\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    460\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 462\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "out = lst(df,500056565, 100278,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "merged = list(itertools.chain(*out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7270129919052124,\n",
       " 0.6565780639648438,\n",
       " 0.4383182227611542,\n",
       " 0.37980788946151733,\n",
       " 0.48490405082702637,\n",
       " 0.6320451498031616,\n",
       " 0.40920087695121765,\n",
       " 0.4067407548427582,\n",
       " 0.4210392236709595,\n",
       " 0.4217166006565094,\n",
       " 0.4004535675048828,\n",
       " 0.4013412892818451]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7270129919052124],\n",
       " [0.6565780639648438],\n",
       " [0.4383182227611542],\n",
       " [0.37980788946151733],\n",
       " [0.48490405082702637],\n",
       " [0.6320451498031616],\n",
       " [0.40920087695121765],\n",
       " [0.4067407548427582],\n",
       " [0.4210392236709595],\n",
       " [0.4217166006565094],\n",
       " [0.4004535675048828],\n",
       " [0.4013412892818451]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
