{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense  \n",
    "from keras.layers import LSTM  \n",
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/bharat/proj/time_series1/4200_C005_2019_03_03.tsv\"\n",
    "df = pd.read_csv(file_path, sep=',', header=None)\n",
    "df.columns = [\"kunag\", \"matnr\", \"date\", \"quantity\",\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_series(input_df,kunag,matnr):\n",
    "    input_df = input_df[input_df[\"quantity\"] >=0]    \n",
    "    df = input_df.copy()\n",
    "    n_df1 = df[(df[\"kunag\"] == kunag) & (df[\"matnr\"] == matnr)]\n",
    "    n_df1.date = n_df1.date.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))\n",
    "    n_df1 = n_df1.sort_values('date')\n",
    "    n_df1.set_index('date',inplace=True)\n",
    "    weekly_resampled_data = n_df1.quantity.resample('W').sum() \n",
    "    weekly_resampled_data = weekly_resampled_data.replace(np.nan, 0)\n",
    "    individual_series = weekly_resampled_data.to_frame()\n",
    "    individual_series = individual_series.reset_index()\n",
    "    return individual_series\n",
    "\n",
    "\n",
    "def train_test_split(input_df,kunag,matnr,i):\n",
    "    data= n_series(input_df,kunag,matnr)\n",
    "    train = data[0:-i]    \n",
    "    test = data[-i:]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=  train_test_split(df,500056565,100278,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = n_series(df,500056565, 100278)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "order = 16\n",
    "test_points = 16\n",
    "df_testing_complete = pd.read_csv(r'testing.csv')\n",
    "test_predictions = []\n",
    "print(dataframe[102:])\n",
    "for k in range(0, test_points):\n",
    "    df = dataframe[:-test_points + k]\n",
    "    df_training_complete = df\n",
    "    print(df_training_complete.shape)\n",
    "  \n",
    "    df_training_processed = df_training_complete.iloc[:, 1:2].values  \n",
    "\n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    df_training_scaled = scaler.fit_transform(df_training_processed)  \n",
    "\n",
    "    features_set = []  \n",
    "    labels = []  \n",
    "    for i in range(order , df.shape[0] - 1):  \n",
    "        features_set.append(df_training_scaled[i-order:i, 0])\n",
    "        labels.append(df_training_scaled[i, 0])\n",
    "    \n",
    "    print(\"X\", features_set[-1])\n",
    "    features_set, labels = np.array(features_set), np.array(labels)  \n",
    "    features_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))  \n",
    "    print(features_set.size)\n",
    "    model = Sequential()  \n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(features_set.shape[1], 1)))  \n",
    "    model.add(Dropout(0.2))  \n",
    "    model.add(LSTM(units=50, return_sequences=True))  \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=True))  \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50))  \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 1))  \n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')  \n",
    "    \n",
    "    model.fit(features_set, labels, epochs = 5, batch_size = 32)  \n",
    "    df_testing_processed = df_testing_complete.iloc[k:k+1, 1:2].values \n",
    "    df_total = pd.concat((df_training_complete['quantity'], df_testing_complete['quantity']), axis=0)  \n",
    "    test_inputs = df_total[len(df_total) - len(df_testing_complete) - order + k:].values  \n",
    "    test_inputs = test_inputs.reshape(-1,1)  \n",
    "    test_inputs = scaler.transform(test_inputs) \n",
    "\n",
    "    test_features = []   \n",
    "    test_features.append(test_inputs[0:order, 0])\n",
    "    \n",
    "    test_features = np.array(test_features)  \n",
    "    test_features = np.reshape(test_features, (test_features.shape[0], test_features.shape[1], 1))\n",
    "    print(\"Y\", test_features[-1][-1][-1])\n",
    "    predictions = model.predict(test_features)  \n",
    "    predictions = scaler.inverse_transform(predictions)  \n",
    "    test_predictions.append(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_1 = [i[0][0] for i in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=  train_test_split(df,500056565,100278,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.DataFrame(data=test_predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(inplace = True)\n",
    "pred = pd.concat([test, df_c], axis=1, join_axes=[test.index])\n",
    "pred.set_index(\"date\",inplace = True)\n",
    "del pred[\"index\"]\n",
    "del pred[\"quantity\"]\n",
    "del test[\"index\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae = mean_absolute_error(test.quantity, pred[0])\n",
    "rms = sqrt(mean_squared_error(test.quantity, pred[0]))\n",
    "print(\"mae :\",mae)\n",
    "print(\"rms :\",rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.set_index('date',inplace=True)\n",
    "train.set_index('date',inplace=True)\n",
    "test.set_index('date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot( dataframe, marker='.', color='blue')\n",
    "plt.plot( train, marker='.', color='blue')\n",
    "plt.plot( test, marker='.', color='orange')\n",
    "plt.plot(pred,marker = \".\",color = 'green')\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel('quantity')\n",
    "# plt.savefig(\"/home/rahul/Downloads/bharat/time_series1/high_freq_plots/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = Sequential()  \n",
    "# model.add(LSTM(units=50, return_sequences=True, input_shape=(features_set.shape[1], 1)))  \n",
    "# model.add(Dropout(0.2))  \n",
    "# model.add(LSTM(units=50, return_sequences=True))  \n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(units=50, return_sequences=True))  \n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(units=50))  \n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(units = 1))  \n",
    "# model.compile(optimizer = 'adam', loss = 'mean_squared_error')  \n",
    "# model.fit(features_set, labels, epochs = 100, batch_size = 32)  \n",
    "# df_testing_complete = pd.read_csv(r'testing.csv')  \n",
    "# df_testing_processed = df_testing_complete.iloc[:, 1:2].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_total = pd.concat((df_training_complete['quantity'], df_testing_complete['quantity']), axis=0)  \n",
    "# test_inputs = df_total[len(df_total) - len(df_testing_complete) - 16:].values  \n",
    "# test_inputs = test_inputs.reshape(-1,1)  \n",
    "# test_inputs = scaler.transform(test_inputs) \n",
    "\n",
    "# test_features = []  \n",
    "# for i in range(16, 16 + 1):  \n",
    "#     test_features.append(test_inputs[i-16:i, 0])\n",
    "    \n",
    "# test_features = np.array(test_features)  \n",
    "# test_features = np.reshape(test_features, (test_features.shape[0], test_features.shape[1], 1))\n",
    "\n",
    "# predictions = model.predict(test_features)  \n",
    "# predictions = scaler.inverse_transform(predictions)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
