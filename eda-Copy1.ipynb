{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Invmovements.csv\",sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Inventory_main.csv',sep = \"|\",index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = data.head(100)\n",
    "\n",
    "# export_csv = exp.to_csv (r'Inventory(100).csv',sep = \",\", index = None, header=True)\n",
    "\n",
    "# data1 = pd.read_csv(\"Inventory(100).csv\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1.to_csv('Invmovements.csv') \n",
    "data1.to_csv('Invmovements.csv',sep = \",\",index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/home/bharat/proj/hackathon/File_Invmovements_01.csv\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data[\"StorageLocation\"]<200]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data1[data1[\"Plant\"] == \"C002\"]\n",
    "\n",
    "df1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = data[data[\"Plant\"] == \"C002\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns = {\"MaterialNumber_MARC\": \"MaterialNumber\"}, \n",
    "                                 inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = df1[[\"MovementType\",\"DebitCreditInd\"]].groupby([\"MovementType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.get_group(551)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge = df1.merge(df2,on = [\"MaterialNumber\"],how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df1[\"MaterialNumber\"].unique()))\n",
    "\n",
    "k1 = df1[\"MaterialNumber\"].unique()\n",
    "arr1 = np.sort(k1, axis = None)         \n",
    "\n",
    "# arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df2[\"MaterialNumber\"].unique()))\n",
    "\n",
    "k2 = df2[\"MaterialNumber\"].unique()\n",
    "arr2 = np.sort(k2, axis = None)         \n",
    "\n",
    "arr2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for i in range(0,len(arr1)):\n",
    "#     for j in range(0,len(arr2)):\n",
    "#         if(arr1[i]==arr2[j]):\n",
    "#             cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df2= df2[[\"StorageLocation\",\"MaterialNumber\",\"PostingDate\",\"ClosingStock_SUM_SUM\"]]\n",
    "main_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1.MovementType.isin([101, 102, 261, 262, 551])]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df1  = df1[[\"PostingDate\",\"StorageLocation\",\"MaterialNumber\",\"MovementType\",\"Quantity_SUM\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[df1[\"MaterialNumber_MARC\"] == 150000013 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df2.PostingDate = main_df2.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = main_df2.groupby([\"MaterialNumber\",\"StorageLocation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/home/bharat/proj/hackathon/graphs/Inventory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,200):\n",
    "    try:        \n",
    "        group = grouped.get_group((arr1[i],30))\n",
    "        plt.figure(figsize=(16,8))\n",
    "        plt.plot( group.set_index([\"PostingDate\"])[\"ClosingStock_SUM_SUM\"], marker='.', label=arr1[i])\n",
    "        plt.title(arr1[i])\n",
    "        plt.xlabel(\"time\")\n",
    "        plt.ylabel('quantity')\n",
    "        plt.legend()\n",
    "        plt.savefig(\"/home/bharat/proj/hackathon/graphs/Inventory/C002/\" + 'Graph_{}.png'.format(arr1[i]), format=\"PNG\")  \n",
    "        plt.close(plt)    # close the figure\n",
    "    except:\n",
    "            pass  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.sort_values([\"MaterialDocument\", \"MaterialNumber_MARC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data.loc[data[\"StorageLocation\"]<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Plant\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"PostingDate\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"PostingDate\"].min(), data[\"PostingDate\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"PostingDate\"].sort_values().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"PostingDate\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. StorageLocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"StorageLocation\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"StorageLocation\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PlantName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"PlantName\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"PlantName\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MaterialType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"MaterialType\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = data[\"MaterialType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.sort(k, axis = None)         \n",
    "\n",
    "arr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. MaterialType_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"MaterialType_description\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MaterialType_description\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. MaterialNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"MaterialNumber\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MaterialNumber\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MaterialNumber\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. ClosingStock_SUM_SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"ClosingStock_SUM_SUM\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"ClosingStock_SUM_SUM\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data[\"ClosingStock_SUM_SUM\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.groupby(\"MovementType\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data[data[\"Plant\"] == \"C002\"]\n",
    "\n",
    "print(df1.shape)\n",
    "\n",
    "print(df1[\"MovementType\"].value_counts().sum())\n",
    "\n",
    "df1[\"MovementType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = data[data[\"Plant\"] == \"C004\"]\n",
    "\n",
    "print(df2.shape)\n",
    "\n",
    "print(df2[\"MovementType\"].value_counts().sum())\n",
    "\n",
    "df2[\"MovementType\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. MovementTypeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"MovementTypeText\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MovementTypeText\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = data[data[\"Plant\"] == \"C002\"]\n",
    "\n",
    "print(df3.shape)\n",
    "\n",
    "print(df3[\"MovementTypeText\"].value_counts().sum())\n",
    "\n",
    "df3[\"MovementTypeText\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = data[data[\"Plant\"] == \"C004\"]\n",
    "\n",
    "print(df4.shape)\n",
    "\n",
    "print(df4[\"MovementTypeText\"].value_counts().sum())\n",
    "\n",
    "df4[\"MovementTypeText\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"MovementType\", \"MovementTypeText\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. DebitCreditInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DebitCreditInd\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Quantity_SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"Quantity_SUM\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = data[\"Quantity_SUM\"].unique()\n",
    "arr = np.median(l,axis = None)\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. MaterialDocument_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MaterialDocument_COUNT\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[[\"MaterialNumber_MARC\", \"MaterialDescription\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[[\"MaterialNumber_MARC\",\"MaterialDescription\"]].groupby('MaterialNumber_MARC').count().reset_index()[\"MaterialDescription\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = data[[\"MaterialNumber_MARC\",\"MaterialDescription\"]].groupby('MaterialNumber_MARC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b.get_group(150034849)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data[[\"MaterialNumber_MARC\",\"MaterialDescription\"]].groupby('MaterialNumber_MARC').nunique()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = data[[\"MaterialNumber_MARC\",\"MaterialDescription\"]].groupby('MaterialDescription')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (data[[\"MaterialNumber_MARC\",\"MaterialDescription\"]].groupby('MaterialDescription').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data[data[\"Plant\"] == \"C004\"]\n",
    "\n",
    "df.shape\n",
    "\n",
    "df[\"MovementType\"].value_counts().sum()\n",
    "\n",
    "df[\"MovementType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_df1.shape)\n",
    "main_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df1.StorageLocation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_df2.shape)\n",
    "main_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_df2[main_df2[\"MaterialNumber\"] == 150000004 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df2.StorageLocation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = main_df1.merge(main_df2,on = [\"MaterialNumber\",\"StorageLocation\",\"PostingDate\"],how = \"inner\")\n",
    "\n",
    "# pd.merge(main_df1, main_df2, on=[\"MaterialNumber\",\"StorageLocation\",\"PostingDate\"])\n",
    "\n",
    "df_merge.shape\n",
    "\n",
    "df_merge.head()\n",
    "\n",
    "df_merge.StorageLocation.value_counts()\n",
    "\n",
    "df_merge.MovementType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for index,group in df_merge.groupby([\"MaterialNumber\"]):\n",
    "#     plt.figure(figsize=(16,8))\n",
    "#     print(index)\n",
    "#     for index2,group2 in group.groupby([\"MovementType\"]):\n",
    "# #         print(index2)  \n",
    "#         print()\n",
    "#         plt.plot( group2.set_index([\"PostingDate\"])[\"Quantity_SUM\"], marker='.', label=index2)\n",
    "#         plt.plot( group2.set_index([\"PostingDate\"])[\"ClosingStock_SUM_SUM\"], marker='.', label=\"Net_Q\",color = \"black\")\n",
    "\n",
    "#         plt.title(index)\n",
    "#     plt.xlabel(\"time\")\n",
    "#     plt.ylabel('quantity')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "# #     plt.savefig(\"/home/bharat/proj/hackathon/graphs/C004/new/\" + 'Graph_{}.png'.format(index), format=\"PNG\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW_ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOR C002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov1 = data1[data1[\"Plant\"] == \"C002\"]\n",
    "df_mov1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inv1 = data[data[\"Plant\"] == \"C002\"]\n",
    "df_inv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inv1.StorageLocation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov1.StorageLocation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mov1 = df_mov1[df_mov1.StorageLocation.isin([30,35])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df2.head()\n",
    "main_df2.PostingDate = main_df2.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = main_df2.groupby([\"MaterialNumber\",\"PostingDate\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp.StorageLocation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = grp[grp[\"StorageLocation\"]==30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp.get_group((150000001,20170614.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del grp[\"StorageLocation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = grp.reset_index()\n",
    "grp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(grp[\"ClosingStock_SUM_SUM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for index,group in grp.groupby([\"MaterialNumber\"]):\n",
    "#     plt.figure(figsize=(16,8))\n",
    "#     print(index)\n",
    "# #     plt.plot( group2.set_index([\"PostingDate\"])[\"Quantity_SUM\"], marker='.', label=index2)\n",
    "#     plt.plot( group.set_index([\"PostingDate\"])[\"ClosingStock_SUM_SUM\"], marker='.', label=\"Net_Q\")\n",
    "\n",
    "#     plt.title(index)\n",
    "#     plt.xlabel(\"time\")\n",
    "#     plt.ylabel('quantity')\n",
    "#     plt.legend()\n",
    "# #     plt.show()\n",
    "#     plt.savefig(\"/home/bharat/proj/hackathon/graphs/Inventory/C002/\" + 'Graph_{}.png'.format(index), format=\"PNG\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df1.StorageLocation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df1 = main_df1[main_df1[\"StorageLocation\"]==30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp1 = main_df1.groupby([\"MaterialNumber\",\"MovementType\",\"PostingDate\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp1 = grp1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for index,group in grp1.groupby([\"MaterialNumber\"]):\n",
    "#     plt.figure(figsize=(16,8))\n",
    "#     print(index)\n",
    "#     for index2,group2 in group.groupby([\"MovementType\"]):\n",
    "# #         print(index2)  \n",
    "#         print()\n",
    "#         plt.plot( group2.set_index([\"PostingDate\"])[\"Quantity_SUM\"], marker='.', label=index2)\n",
    "#         plt.title(index)\n",
    "#     plt.xlabel(\"time\")\n",
    "#     plt.ylabel('quantity')\n",
    "#     plt.legend()\n",
    "# #     plt.show()\n",
    "#     plt.savefig(\"/home/bharat/proj/hackathon/graphs/NC002/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOR C004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov = data[data[\"Plant\"] == \"C004\"]\n",
    "df_mov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "150000027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inv = data[data[\"Plant\"] == \"C004\"]\n",
    "df_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mov.PostingDate = df_mov.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))\n",
    "df_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inv = df_inv[df_inv.StorageLocation.isin([30])]\n",
    "df_inv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inv.StorageLocation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov.StorageLocation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sort(df_mov.Quantity_SUM.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov.MovementType.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov = df_mov[df_mov.MovementType.isin([261])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mov = df_mov[df_mov.MovementType.isin([101, 102,122,251, 261, 262,301,309,315,351, 551,552,561,562,701,702,310,641,642])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov.rename(columns = {\"MaterialNumber_MARC\": \"MaterialNumber\"}, \n",
    "                                 inplace = True) \n",
    "df_mov  = df_mov[[\"PostingDate\",\"StorageLocation\",\"MaterialNumber\",\"MovementType\",\"DebitCreditInd\",\"Quantity_SUM\"]]\n",
    "\n",
    "df_mov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_mov['Quantity_SUM'].loc[grp_mov['MovementType'].isin([102,122,251,261,301,309,351,551,702,310,641])] = -grp_mov[\"Quantity_SUM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mov['Quantity_SUM'].loc[df_mov['DebitCreditInd'].isin([\"H\"])] = -df_mov[\"Quantity_SUM\"]\n",
    "# df_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov = df_mov.groupby([\"MaterialNumber\",\"MovementType\",\"PostingDate\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov = grp_mov.reset_index()\n",
    "# grp_mov.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for index,group in grp_mov.groupby([\"MaterialNumber\"]):\n",
    "#     plt.figure(figsize=(16,8))\n",
    "#     print(index)\n",
    "#     for index2,group2 in group.groupby([\"MovementType\"]):\n",
    "# #         print(index2)  \n",
    "#         print()\n",
    "#         plt.plot( group2.set_index([\"PostingDate\"])[\"Quantity_SUM\"], marker='.', label=index2)\n",
    "#         plt.title(index)\n",
    "#     plt.xlabel(\"time\")\n",
    "#     plt.ylabel('quantity')\n",
    "#     plt.legend()\n",
    "# #     plt.show()\n",
    "#     plt.savefig(\"/home/bharat/proj/hackathon/graphs/NC004/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov.PostingDate = grp_mov.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del grp_mov[\"StorageLocation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_mov['Quantity_SUM'].loc[grp_mov['MovementType'].isin([102,122,251,261,301,309,351,551,702,310,641])] = -grp_mov[\"Quantity_SUM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov = grp_mov.sort_values(by = 'PostingDate')\n",
    "del grp_mov[\"StorageLocation\"]\n",
    "grp_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inv1= df_inv1[[\"StorageLocation\",\"MaterialNumber\",\"PostingDate\",\"ClosingStock_SUM_SUM\"]]\n",
    "df_inv1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inv1.StorageLocation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_inv = df_inv1.groupby([\"MaterialNumber\",\"PostingDate\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_inv = grp_inv.reset_index()\n",
    "del grp_inv[\"StorageLocation\"]\n",
    "grp_inv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_inv.PostingDate = grp_inv.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_inv_m = grp_inv.groupby([\"MaterialNumber\"])\n",
    "# group3 = grp_inv_m.get_group(150000002)\n",
    "# group3.PostingDate = group3.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))\n",
    "# group3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_inv_m = grp_inv.groupby([\"MaterialNumber\"])\n",
    "# for index,group in grp_mov.groupby([\"MaterialNumber\"]):\n",
    "#     plt.figure(figsize=(16,8))\n",
    "#     print(index)\n",
    "#     for index2,group2 in group.groupby([\"MovementType\"]):\n",
    "#         group3 = grp_inv_m.get_group(index)\n",
    "#         group3.PostingDate = group3.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))        \n",
    "#         plt.plot( group3.set_index([\"PostingDate\"])[\"ClosingStock_SUM_SUM\"], color = \"magenta\")\n",
    "#         plt.plot( group2.set_index([\"PostingDate\"])[\"Quantity_SUM\"], marker='.', label=index2)\n",
    "#         plt.title(index)\n",
    "#     plt.xlabel(\"time\")\n",
    "#     plt.ylabel('quantity')\n",
    "#     plt.legend()\n",
    "# #     plt.show()\n",
    "#     plt.savefig(\"/home/bharat/proj/hackathon/graphs/MC004/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del grp_mov[\"MovementType\"]\n",
    "grp_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_mov[\"diff\"] = df_merge[\"ClosingStock_SUM_SUM\"] - df_merge[\"Quantity_SUM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_inv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group[\"cumulative\"] = group[\"Quantity_SUM\"].cumsum(axis = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grp_inv_m = grp_inv.groupby([\"MaterialNumber\"])\n",
    "# grp_merge = df_merge.groupby([\"MaterialNumber\"])\n",
    "for index,group in grp_mov.groupby([\"MaterialNumber\"]):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    print(index)\n",
    "#     print(group)\n",
    "    group[\"cumulative\"] = group[\"Quantity_SUM\"].cumsum(axis = 0) \n",
    "    group2 = grp_inv_m.get_group(index)\n",
    "    \n",
    "    \n",
    "    group2.PostingDate = group2.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))        \n",
    "    plt.plot( group2.set_index([\"PostingDate\"])[\"ClosingStock_SUM_SUM\"], color = \"magenta\",label = \"Inventory level\")\n",
    "    plt.plot( group.set_index([\"PostingDate\"])[\"cumulative\"], marker='.', label=index)\n",
    "#     plt.plot( group.set_index([\"PostingDate\"])[\"diff\"], marker='.', label=\"diff\",color = 'green')\n",
    "\n",
    "    plt.title(index)\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel('quantity')\n",
    "    plt.legend()\n",
    "#     plt.show()\n",
    "    plt.savefig(\"/home/bharat/proj/hackathon/graphs/inc_allC002/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     group[[\"cumulative\", \"Quantity_SUM\"]] = group[[\"cumulative\", \"Quantity_SUM\"]].apply(pd.to_numeric)\n",
    "#     group[\"cumulative\"] =  pd.to_numeric(group[\"cumulative\"])\n",
    "#     group = group.apply(pd.to_numeric)\n",
    "#     group.astype({'cumulative': 'int32','Quantity_SUM': 'int32'}).dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_inv_m = grp_inv.groupby([\"MaterialNumber\"])\n",
    "# grp_merge = df_merge.groupby([\"MaterialNumber\"])\n",
    "# for index,group in grp_mov.groupby([\"MaterialNumber\"]):\n",
    "#     plt.figure(figsize=(16,8))\n",
    "#     print(index)\n",
    "\n",
    "#     group[\"cumulative\"] = group[\"Quantity_SUM\"].cumsum(axis = 0)\n",
    "#     group2 = grp_inv_m.get_group(index)\n",
    "#     group3 = grp_merge.get_group(index)\n",
    "# #     print(group3.head())\n",
    "    \n",
    "# #     print(type(group))\n",
    "\n",
    "# #     print(type(group[\"cumulative\"]))\n",
    "#     group[\"diff\"] = group3[\"ClosingStock_SUM_SUM\"] - group[\"Quantity_SUM\"]\n",
    "#     group[\"ClosingStock_SUM_SUM\"] = group3[\"ClosingStock_SUM_SUM\"]\n",
    "#     del group[\"Quantity_SUM\"]\n",
    "#     print(group.head())\n",
    "#     group2.PostingDate = group2.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))        \n",
    "#     plt.plot( group2.set_index([\"PostingDate\"])[\"ClosingStock_SUM_SUM\"], color = \"magenta\",label = \"Inventory level\")\n",
    "#     plt.plot( group.set_index([\"PostingDate\"])[\"cumulative\"], marker='.', label=\"Cumulative\")\n",
    "#     plt.plot( group.set_index([\"PostingDate\"])[\"diff\"], marker='.', label=\"Difference\",color = 'green')\n",
    "\n",
    "#     plt.title(index)\n",
    "#     plt.xlabel(\"time\")\n",
    "#     plt.ylabel('quantity')\n",
    "#     plt.legend()\n",
    "# #     plt.show()\n",
    "#     plt.savefig(\"/home/bharat/proj/hackathon/graphs/main_diff1C002/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = grp_inv.merge(grp_mov,on = [\"MaterialNumber\",\"PostingDate\"],how = \"inner\")\n",
    "\n",
    "# pd.merge(main_df1, main_df2, on=[\"MaterialNumber\",\"StorageLocation\",\"PostingDate\"])\n",
    "\n",
    "print(df_merge.shape)\n",
    "\n",
    "print(df_merge.head())\n",
    "\n",
    "# print(df_merge.StorageLocation.value_counts())\n",
    "\n",
    "# print(df_merge.MovementType.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_merge[\"MovementType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# grp_inv_m = grp_inv.groupby([\"MaterialNumber\"])\n",
    "for index,group in df_merge.groupby([\"MaterialNumber\"]):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    print(index)\n",
    "#     print(group)\n",
    "    group[\"cumulative\"] = group[\"Quantity_SUM\"].cumsum(axis = 0) \n",
    "#     group2 = grp_inv_m.get_group(index)\n",
    "#     group2.PostingDate = group2.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))        \n",
    "    plt.plot( group.set_index([\"PostingDate\"])[\"ClosingStock_SUM_SUM\"], color = \"magenta\",label = \"Inventory level\")\n",
    "    plt.plot( group.set_index([\"PostingDate\"])[\"cumulative\"], marker='.', label=index)\n",
    "    plt.title(index)\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel('quantity')\n",
    "    plt.legend()\n",
    "#     plt.show()\n",
    "    plt.savefig(\"/home/bharat/proj/hackathon/graphs/merged_df_C002/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#     for index2,group2 in group.groupby([\"MovementType\"]):\n",
    "#         group3 = grp_inv_m.get_group(index)\n",
    "#         group3.PostingDate = group3.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))        \n",
    "#         plt.plot( group3.set_index([\"PostingDate\"])[\"ClosingStock_SUM_SUM\"], color = \"magenta\")\n",
    "#         plt.plot( group2.set_index([\"PostingDate\"])[\"cumulative\"], marker='.', label=index2)\n",
    "#         plt.title(index)\n",
    "#     plt.xlabel(\"time\")\n",
    "#     plt.ylabel('quantity')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "#     plt.savefig(\"/home/bharat/proj/hackathon/graphs/MC004/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# grp_inv_m = grp_inv.groupby([\"MaterialNumber\"])\n",
    "# for index,group in grp_mov.groupby([\"MaterialNumber\"]):\n",
    "#     plt.figure(figsize=(16,8))\n",
    "#     print(index)\n",
    "#     for index2,group2 in group.groupby([\"MovementType\"]):\n",
    "#         group3 = grp_inv_m.get_group(index)\n",
    "#         group3.PostingDate = group3.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))        \n",
    "#         plt.plot( group3.set_index([\"PostingDate\"])[\"ClosingStock_SUM_SUM\"], color = \"magenta\")\n",
    "#         plt.plot( group2.set_index([\"PostingDate\"])[\"Quantity_SUM\"], marker='.', label=index2)\n",
    "#         plt.title(index)\n",
    "#     plt.xlabel(\"time\")\n",
    "#     plt.ylabel('quantity')\n",
    "#     plt.legend()\n",
    "# #     plt.show()\n",
    "#     plt.savefig(\"/home/bharat/proj/hackathon/graphs/MC004/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_date = \"20190630\"\n",
    "\n",
    "# current_date = pd.to_datetime(current_date, format=\"%Y%m%d\")\n",
    "# ff = current_date - timedelta(days = 730)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_date = \"20190630\"\n",
    "\n",
    "# current_date = pd.to_datetime(current_date, format=\"%Y%m%d\")\n",
    "# group3 = group3.apply(lambda x: x[\"PostingDate\"].between(current_date, current_date-pd.to_timedelta(730, unit='d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mov = df_mov[df_mov.MovementType.isin([101, 102, 261, 262, 551])]\n",
    "df_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov = df_mov.groupby([\"MaterialNumber\",\"MovementType\",\"PostingDate\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov1 = grp_mov.reset_index()\n",
    "del grp_mov1[\"StorageLocation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_mov.StorageLocation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov2 = grp_mov1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov2['Quantity_SUM'].loc[grp_mov2['MovementType'].isin([102,261,551])] = -grp_mov2[\"Quantity_SUM\"]\n",
    "# grp_mov2['Quantity_SUM'].loc[grp_mov2['MovementType'] == 101] = -grp_mov2[\"Quantity_SUM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpd = grp_mov2.groupby(\"MaterialNumber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = grpd.get_group(150000006)\n",
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n[\"cumulative\"] = df_n[\"Quantity_SUM\"].cumsum(axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov[\"PostingDate\"] = df_mov[\"PostingDate\"].apply(lambda x: pd.to_datetime(x, format=\"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"frequency\"] = df[\"frequency\"].apply(lambda x: pd.to_datetime(x, format=\"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_mov2['Quantity_SUM'].loc[grp_mov2['MovementType'].isin([102,261,551])] = -grp_mov2[\"Quantity_SUM\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_inv_m = grp_inv.groupby([\"MaterialNumber\"])\n",
    "for index,group in grp_mov.groupby([\"MaterialNumber\"]):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    print(index)\n",
    "    for index2,group2 in group.groupby([\"MovementType\"]):\n",
    "        group3 = grp_inv_m.get_group(index)\n",
    "        group3.PostingDate = group3.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))        \n",
    "        plt.plot( group3.set_index([\"PostingDate\"])[\"ClosingStock_SUM_SUM\"], color = \"magenta\")\n",
    "        plt.plot( group2.set_index([\"PostingDate\"])[\"Quantity_SUM\"], marker='.', label=index2)\n",
    "        plt.title(index)\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel('quantity')\n",
    "    plt.legend()\n",
    "#     plt.show()\n",
    "    plt.savefig(\"/home/bharat/proj/hackathon/graphs/MC004/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index,group in grp_mov.groupby([\"MaterialNumber\"]):\n",
    "#     plt.figure(figsize=(16,8))\n",
    "#     print(index)\n",
    "# #     print(group)\n",
    "# #     group[\"cumulative\"] = group[\"Quantity_SUM\"].cumsum(axis = 0)     \n",
    "#     plt.plot( group.set_index([\"PostingDate\"])[\"Quantity_SUM\"], marker='.', label=index)\n",
    "# #     plt.plot( group.set_index([\"PostingDate\"])[\"diff\"], marker='.', label=\"diff\",color = 'green')\n",
    "\n",
    "#     plt.title(index)\n",
    "#     plt.xlabel(\"time\")\n",
    "#     plt.ylabel('quantity')\n",
    "#     plt.legend()\n",
    "# #     plt.show()\n",
    "#     plt.savefig(\"/home/bharat/proj/hackathon/graphs/solnC004/\" + 'Graph_{}.png'.format(index), format=\"PNG\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index,group in grp_mov.groupby([\"MaterialNumber\"]):\n",
    "#     print(group.head())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##n_series to find the individual series for a kunag,matnr combination\n",
    "def n_series(input_df,matnr): \n",
    "    df = input_df.copy()\n",
    "#     print(df.head())\n",
    "#     print(\"matnr :\",matnr)\n",
    "    n_df1 = df[(df[\"MaterialNumber\"] == matnr)]\n",
    "#     print(n_df1.head())\n",
    "\n",
    "    #sort date start to end\n",
    "    n_df1 = n_df1.sort_values('PostingDate')\n",
    "    n_df1.set_index('PostingDate',inplace=True)\n",
    "#     print(n_df1.head())\n",
    "\n",
    "    #sampling the data on weekly basis (index is set to date first in the above step to do weekly sampling\n",
    "    weekly_resampled_data = n_df1.Quantity_SUM.resample('M').sum() \n",
    "    weekly_resampled_data = weekly_resampled_data.replace(np.nan, 0)\n",
    "    individual_series = weekly_resampled_data.to_frame()     \n",
    "    #resetting index so that date can be used as column\n",
    "    individual_series = individual_series.reset_index()\n",
    "    return individual_series\n",
    "\n",
    "#splitting the individual series basesd on the number of weeks (i, is for dyanamic point forecasts)\n",
    "def train_test_split(input_df,matnr,i):\n",
    "    data= n_series(input_df,matnr)\n",
    "    train = data.iloc[0:-i]    \n",
    "    test = data.iloc[-i:]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  for i in range (1,3):\n",
    "#             matnr = int(grp_mov[\"MaterialNumber\"].iloc[i])\n",
    "# #             print(\"count\",cnt)\n",
    "#             print(matnr)\n",
    "# #             train,test = train_test_split(grp_mov,matnr,16)\n",
    "# #             print(train.head())\n",
    "#             df = n_series(grp_mov,matnr)\n",
    "# #             print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(input_df,matnr,n):\n",
    "#     path = \"/home/rahul/Downloads/bharat/time_series1/model_graphs/\"\n",
    "#     folder = path+\"/naive\"\n",
    "#     if not os.path.exists(folder):\n",
    "#         os.makedirs(folder)\n",
    "    index = str(matnr)\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split(input_df,matnr,n)[1]\n",
    "    y_hat = test1.copy()\n",
    "    \n",
    "    for i in range(n,0,-1):\n",
    "        train,test = train_test_split(input_df,matnr,i)\n",
    "        dd= np.asarray(train[\"Quantity_SUM\"])\n",
    "        y_hat['naive'] = int(dd[len(dd)-1])\n",
    "        pred = y_hat['naive']\n",
    "        lst.append(pred.iloc[-1])\n",
    "\n",
    "    \n",
    "    pd.DataFrame(lst)\n",
    "    y_hat['pred_column']=lst\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot( train.set_index(\"PostingDate\")['Quantity_SUM'], label='Train',marker = '.')\n",
    "    plt.plot(test1.set_index(\"PostingDate\")['Quantity_SUM'], label='Test',marker = '.')\n",
    "    plt.plot(y_hat.set_index(\"PostingDate\")['pred_column'], label='Naive Forecast',marker = '.')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Naive Forecast\")\n",
    "#     plt.savefig(folder +\"/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    rms = sqrt(mean_squared_error(test1.Quantity_SUM, y_hat.pred_column))\n",
    "    mae = mean_absolute_error(test1.Quantity_SUM, y_hat.pred_column)\n",
    "    del y_hat['naive']\n",
    "    return y_hat,rms,mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(input_df,matnr,n,roll):\n",
    "\n",
    "    index = str(matnr)\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split(input_df,matnr,n)[1]\n",
    "#     y_hat = test1.copy()\n",
    "    y_hat_avg = test1.copy()\n",
    "\n",
    "    for i in range(n,0,-1):\n",
    "        train,test = train_test_split(input_df,matnr,i)\n",
    "        dd= np.asarray(train[\"Quantity_SUM\"])\n",
    "        y_hat_avg['moving_avg_forecast'] = train['Quantity_SUM'].rolling(roll).mean().iloc[-1]\n",
    "        pred = y_hat_avg['moving_avg_forecast']\n",
    "        lst.append(pred.iloc[-1])\n",
    "\n",
    "    pd.DataFrame(lst)\n",
    "    y_hat_avg['pred_column']=lst\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot( train.set_index(\"PostingDate\")['Quantity_SUM'], label='Train',marker = '.')\n",
    "    plt.plot(test1.set_index(\"PostingDate\")['Quantity_SUM'], label='Test',marker = '.')\n",
    "    plt.plot(y_hat_avg.set_index(\"PostingDate\")['pred_column'], label='moving_avg_forecast',marker = '.')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"moving_avg_forecast\")\n",
    "\n",
    "    plt.show()\n",
    "    rms = sqrt(mean_squared_error(test1.Quantity_SUM, y_hat_avg.pred_column))\n",
    "    mae = mean_absolute_error(test1.Quantity_SUM, y_hat_avg.pred_column)\n",
    "    del y_hat_avg['moving_avg_forecast']\n",
    "    return y_hat_avg,rms,mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima(input_df,matnr,n,p,d,q):\n",
    "\n",
    "    index =str(matnr)\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split(input_df,matnr,n)[1]\n",
    "    y_hat_avg = test1.copy()\n",
    "    start_date = str(test1[\"PostingDate\"][:1])\n",
    "    end_date = str(test1[\"PostingDate\"][-1:])\n",
    "    order = (p, d,q)\n",
    "    for i in range(n,0,-1):\n",
    "        train,test = train_test_split(input_df,matnr,i)\n",
    "        dd= np.asarray(train[\"Quantity_SUM\"])\n",
    "        fit1 = sm.tsa.statespace.SARIMAX(train[\"Quantity_SUM\"], order=order,enforce_stationarity = False, enforce_invertibility = False,trend = \"n\").fit()    \n",
    "        pred = fit1.predict(1)\n",
    "        lst.append(pred.iloc[-1])\n",
    "\n",
    "    pd.DataFrame(lst)\n",
    "    y_hat_avg['pred_column']=lst\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot( train.set_index(\"PostingDate\")['Quantity_SUM'], label='Train',marker = '.')\n",
    "    plt.plot(test1.set_index(\"PostingDate\")['Quantity_SUM'], label='Test',marker = '.')\n",
    "    plt.plot(y_hat_avg.set_index(\"PostingDate\")['pred_column'], label='ARIMA' + \"_\" + str(order),marker = '.')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"SARIMA\")\n",
    "\n",
    "#     plt.savefig(folder +\"/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n",
    "\n",
    "    plt.show()\n",
    "    rms = sqrt(mean_squared_error(test1.Quantity_SUM, y_hat_avg.pred_column))\n",
    "    mae = mean_absolute_error(test1.Quantity_SUM, y_hat_avg.pred_column)\n",
    "    return y_hat_avg,rms,mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ses(input_df,matnr,n,alpha):\n",
    "\n",
    "    index =  str(matnr)\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split(input_df,matnr,n)[1]\n",
    "    y_hat_avg = test1.copy()\n",
    "    for i in range(n,0,-1):\n",
    "        train,test = train_test_split(input_df,matnr,i)\n",
    "        dd= np.asarray(train[\"Quantity_SUM\"])\n",
    "        fit2 = SimpleExpSmoothing(np.asarray(train['Quantity_SUM'])).fit(smoothing_level=alpha,optimized=False)\n",
    "        y_hat_avg['SES'] = fit2.forecast(len(test1))\n",
    "        pred = y_hat_avg['SES']\n",
    "        lst.append(pred.iloc[-1])\n",
    "\n",
    "    pd.DataFrame(lst)\n",
    "    y_hat_avg['pred_column']=lst\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot( train.set_index(\"PostingDate\")['Quantity_SUM'], label='Train')\n",
    "    plt.plot(test1.set_index(\"PostingDate\")['Quantity_SUM'], label='Test')\n",
    "    plt.plot(y_hat_avg.set_index(\"PostingDate\")['pred_column'], label='SES',marker = \".\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"SES\")\n",
    "#     plt.savefig(folder +\"/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n",
    "\n",
    "    plt.show()\n",
    "    rms = sqrt(mean_squared_error(test1.Quantity_SUM, y_hat_avg.pred_column))\n",
    "    mae = mean_absolute_error(test1.Quantity_SUM, y_hat_avg.pred_column)\n",
    "    del y_hat_avg['SES']\n",
    "    return y_hat_avg,rms,mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_mov.groupby([\"MaterialNumber\"]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (0,5):\n",
    "            matnr = int(grp_mov[\"MaterialNumber\"].iloc[i])\n",
    "#             print(\"count\",cnt)\n",
    "            print(\"index : \",matnr)\n",
    "            output1,rms1,mae1 = naive(grp_mov,matnr,4)\n",
    "            output2,rms2,mae2 = moving_average(grp_mov,matnr,4,4)\n",
    "            output3,rms3,mae3 = sarima(grp_mov,matnr,4,0,1,1)\n",
    "            output4,rms4,mae4 = ses(grp_mov,matnr,4,0.2)\n",
    "            print(\"naive :\",rms1)\n",
    "            print(\"moving_average :\",rms2)\n",
    "            print(\"arimas :\",rms3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
