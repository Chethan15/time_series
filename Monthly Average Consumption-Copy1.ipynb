{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mov =pd.read_csv(\"Invmovements.csv\",sep = \",\")\n",
    "# data = pd.read_csv(\"Invmovements.csv\",sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mov = in_mov[in_mov['Plant']=='C004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mov.StorageLocation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mov.StorageLocation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_mov = in_mov[in_mov['StorageLocation'].isin([30,35])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mov = in_mov[in_mov['MovementType'].isin([261])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mov.PostingDate = in_mov.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " in_mov['mnth_yr'] = in_mov['PostingDate'].apply(lambda x: x.strftime('%B-%Y')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mov.mnth_yr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_agg_data = pd.DataFrame({'Qty_consumed':in_mov.groupby(['MaterialNumber_MARC','mnth_yr'])['Quantity_SUM'].sum(),\n",
    "                                'mov_count':in_mov.groupby(['MaterialNumber_MARC','mnth_yr'])['PostingDate'].count()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_agg_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mavg_qty_freq = pd.DataFrame({'mavg_qty':monthly_agg_data.groupby(['MaterialNumber_MARC'])['Qty_consumed'].mean(),\n",
    "                              'Freq':monthly_agg_data.groupby(['MaterialNumber_MARC'])['mov_count'].mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mavg_qty_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mavg_qty_freq.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mavg_qty_freq['mavg_qty'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mavg_qty_freq['mavg_qty'].quantile([.75,.80,.85,.90,.95,.96,.97,.98,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutoffs for low, medium,high volume are 0-10,10-50,50-max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_volume = mavg_qty_freq[mavg_qty_freq['mavg_qty']<10]['MaterialNumber_MARC'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_volume = mavg_qty_freq[(mavg_qty_freq['mavg_qty']>=10) & (mavg_qty_freq['mavg_qty']<=50)]['MaterialNumber_MARC'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_volume = mavg_qty_freq[mavg_qty_freq['mavg_qty']>50]['MaterialNumber_MARC'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = mavg_qty_freq[mavg_qty_freq['mavg_qty']<60]\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.distplot(q['mavg_qty'],kde=False)\n",
    "plt.axvline(x=10,alpha=1,color='black')\n",
    "plt.axvline(x=50,alpha=1,color='black')\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Volume_cutoffs\")\n",
    "plt.savefig(\"analysis_plots/\" + \"Volume_cutoffs.png\", format=\"PNG\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mavg_qty_freq['Freq'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mavg_qty_freq['Freq'].quantile([.75,.80,.85,.90,.95,.96,.97,.98,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutoffs for low, medium,high volume are 0-1.67,1.67-5,5-max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_frequency = mavg_qty_freq[mavg_qty_freq['Freq']<1.67]['MaterialNumber_MARC'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_frequency = mavg_qty_freq[(mavg_qty_freq['Freq']>=1.67) & (mavg_qty_freq['Freq']<=5)]['MaterialNumber_MARC'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_frequency = mavg_qty_freq[mavg_qty_freq['Freq']>5]['MaterialNumber_MARC'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = mavg_qty_freq[mavg_qty_freq['Freq']<10]\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.distplot(f['Freq'],kde=False)\n",
    "\n",
    "plt.axvline(x=1.67,alpha=1,color='black')\n",
    "plt.axvline(x=5,alpha=1,color='black')\n",
    "\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"frequency_cutoffs\")\n",
    "plt.savefig(\"analysis_plots/\" + \"frequency_cutoffs.png\", format=\"PNG\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Invmovements.csv\",sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov = data[data[\"Plant\"] == \"C004\"]\n",
    "df_mov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov = df_mov[df_mov.MovementType.isin([261])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov.rename(columns = {\"MaterialNumber_MARC\": \"MaterialNumber\"}, \n",
    "                                 inplace = True) \n",
    "df_mov  = df_mov[[\"PostingDate\",\"StorageLocation\",\"MaterialNumber\",\"MovementType\",\"DebitCreditInd\",\"Quantity_SUM\"]]\n",
    "\n",
    "df_mov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov = df_mov.groupby([\"MaterialNumber\",\"MovementType\",\"PostingDate\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov = grp_mov.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov.PostingDate = grp_mov.PostingDate.apply(lambda x : pd.to_datetime(x,format = '%Y%m%d', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov = grp_mov.sort_values(by = 'PostingDate')\n",
    "del grp_mov[\"StorageLocation\"]\n",
    "grp_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del grp_mov[\"MovementType\"]\n",
    "grp_mov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_mov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##n_series to find the individual series for a kunag,matnr combination\n",
    "def n_series(input_df,matnr): \n",
    "    df = input_df.copy()\n",
    "#     print(df.head())\n",
    "#     print(\"matnr :\",matnr)\n",
    "    n_df1 = df[(df[\"MaterialNumber\"] == matnr)]\n",
    "#     print(n_df1.head())\n",
    "\n",
    "    #sort date start to end\n",
    "    n_df1 = n_df1.sort_values('PostingDate')\n",
    "    n_df1.set_index('PostingDate',inplace=True)\n",
    "#     print(n_df1.head())\n",
    "\n",
    "    #sampling the data on weekly basis (index is set to date first in the above step to do weekly sampling\n",
    "    weekly_resampled_data = n_df1.Quantity_SUM.resample('M').sum() \n",
    "    weekly_resampled_data = weekly_resampled_data.replace(np.nan, 0)\n",
    "    individual_series = weekly_resampled_data.to_frame()     \n",
    "    #resetting index so that date can be used as column\n",
    "    individual_series = individual_series.reset_index()\n",
    "    return individual_series\n",
    "\n",
    "#splitting the individual series basesd on the number of weeks (i, is for dyanamic point forecasts)\n",
    "def train_test_split(input_df,matnr,i):\n",
    "    data= n_series(input_df,matnr)\n",
    "    train = data.iloc[0:-i]    \n",
    "    test = data.iloc[-i:]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(input_df,matnr,n,roll):\n",
    "\n",
    "    index = str(matnr)\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split(input_df,matnr,n)[1]\n",
    "#     y_hat = test1.copy()\n",
    "    y_hat_avg = test1.copy()\n",
    "\n",
    "    for i in range(n,0,-1):\n",
    "        train,test = train_test_split(input_df,matnr,i)\n",
    "        dd= np.asarray(train[\"Quantity_SUM\"])\n",
    "        y_hat_avg['moving_avg_forecast'] = train['Quantity_SUM'].rolling(roll).mean().iloc[-1]\n",
    "        pred = y_hat_avg['moving_avg_forecast']\n",
    "        lst.append(pred.iloc[-1])\n",
    "\n",
    "    pd.DataFrame(lst)\n",
    "    y_hat_avg['pred_column']=lst\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot( train.set_index(\"PostingDate\")['Quantity_SUM'], label='Train',marker = '.')\n",
    "    plt.plot(test1.set_index(\"PostingDate\")['Quantity_SUM'], label='Test',marker = '.')\n",
    "    plt.plot(y_hat_avg.set_index(\"PostingDate\")['pred_column'], label='moving_avg_forecast',marker = '.')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(str(matnr)+\"_moving_avg_forecast\")\n",
    "    plt.savefig( \"plots_ma12/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n",
    "\n",
    "#     plt.show()\n",
    "    rms = sqrt(mean_squared_error(test1.Quantity_SUM, y_hat_avg.pred_column))\n",
    "    mae = mean_absolute_error(test1.Quantity_SUM, y_hat_avg.pred_column)\n",
    "    del y_hat_avg['moving_avg_forecast']\n",
    "    return y_hat_avg,rms,mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima(input_df,matnr,n,p,d,q):\n",
    "\n",
    "    index =str(matnr)\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split(input_df,matnr,n)[1]\n",
    "    y_hat_avg = test1.copy()\n",
    "    start_date = str(test1[\"PostingDate\"][:1])\n",
    "    end_date = str(test1[\"PostingDate\"][-1:])\n",
    "    order = (p, d,q)\n",
    "    for i in range(n,0,-1):\n",
    "        train,test = train_test_split(input_df,matnr,i)\n",
    "        dd= np.asarray(train[\"Quantity_SUM\"])\n",
    "        fit1 = sm.tsa.statespace.SARIMAX(train[\"Quantity_SUM\"], order=order,enforce_stationarity = False, enforce_invertibility = False,trend = \"n\").fit()    \n",
    "        pred = fit1.predict(1)\n",
    "        lst.append(pred.iloc[-1])\n",
    "\n",
    "    pd.DataFrame(lst)\n",
    "    y_hat_avg['pred_column']=lst\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot( train.set_index(\"PostingDate\")['Quantity_SUM'], label='Train',marker = '.')\n",
    "    plt.plot(test1.set_index(\"PostingDate\")['Quantity_SUM'], label='Test',marker = '.')\n",
    "    plt.plot(y_hat_avg.set_index(\"PostingDate\")['pred_column'], label='ARIMA' + \"_\" + str(order),marker = '.')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(str(matnr)+\"_ARIMA\")\n",
    "\n",
    "    plt.savefig(\"plots_arima12/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n",
    "\n",
    "#     plt.show()\n",
    "    rms = sqrt(mean_squared_error(test1.Quantity_SUM, y_hat_avg.pred_column))\n",
    "    mae = mean_absolute_error(test1.Quantity_SUM, y_hat_avg.pred_column)\n",
    "    return y_hat_avg,rms,mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Exponential Smoothing\n",
    "def ses(input_df,matnr,n,alpha):\n",
    "\n",
    "    index =  str(matnr)\n",
    "    i = 0\n",
    "    lst = []\n",
    "    test1 = train_test_split(input_df,matnr,n)[1]\n",
    "    y_hat_avg = test1.copy()\n",
    "    for i in range(n,0,-1):\n",
    "        train,test = train_test_split(input_df,matnr,i)\n",
    "        dd= np.asarray(train[\"Quantity_SUM\"])\n",
    "        fit2 = SimpleExpSmoothing(np.asarray(train['Quantity_SUM'])).fit(smoothing_level=alpha,optimized=False)\n",
    "        y_hat_avg['SES'] = fit2.forecast(len(test1))\n",
    "        pred = y_hat_avg['SES']\n",
    "        lst.append(pred.iloc[-1])\n",
    "\n",
    "    pd.DataFrame(lst)\n",
    "    y_hat_avg['pred_column']=lst\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot( train.set_index(\"PostingDate\")['Quantity_SUM'], label='Train')\n",
    "    plt.plot(test1.set_index(\"PostingDate\")['Quantity_SUM'], label='Test')\n",
    "    plt.plot(y_hat_avg.set_index(\"PostingDate\")['pred_column'], label='SES',marker = \".\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(str(matnr)+\"_SES\")\n",
    "    plt.savefig(\"plots_ses12/\" + 'Graph_{}.png'.format(index), format=\"PNG\")  \n",
    "\n",
    "#     plt.show()\n",
    "    rms = sqrt(mean_squared_error(test1.Quantity_SUM, y_hat_avg.pred_column))\n",
    "    mae = mean_absolute_error(test1.Quantity_SUM, y_hat_avg.pred_column)\n",
    "    del y_hat_avg['SES']\n",
    "    return y_hat_avg,rms,mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(low_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(medium_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(high_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving_average(grp_mov,150000005,4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Frequency Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,50):\n",
    "            try:\n",
    "                matnr = low_frequency[i]\n",
    "                print(\"index : \",matnr)\n",
    "                output,rms,mae = moving_average(grp_mov,matnr,12,4)\n",
    "                print(\"moving_average :\",rms)\n",
    "            except :\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium Frequency Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (0,50):\n",
    "            try:\n",
    "                matnr = medium_frequency[i]\n",
    "                print(\"index : \",matnr)\n",
    "                output3,rms3,mae3 = ses(grp_mov,matnr,12,0.2)\n",
    "                print(\"arimas :\",rms3)\n",
    "            except :\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Frequency Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,59):\n",
    "            try:\n",
    "                matnr = high_frequency[i]\n",
    "                print(\"index : \",matnr)\n",
    "                output,rms,mae = arima(grp_mov,matnr,12,0,1,1)\n",
    "                print(\"arima :\",rms)\n",
    "            except :\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = \"011\",\"101\",\"110\",\"111\",\"121\",\"112\",\"211\"\n",
    "df_res= pd.DataFrame(index=None, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_red =pd.DataFrame(OrderedDict({\"matnr\" : [matnr],\n",
    "                    \"011\" : [round(rms1,3)],\n",
    "                   \"101\" : [round(rms2,3)],\n",
    "                   \"110\" : [round(rms3,3)],\n",
    "                   \"111\" : [round(rms4,3)],\n",
    "                   \"211\" : [round(rms5,3)],\n",
    "                   \"121\" : [round(rms6,3)],\n",
    "                   \"112\" : [round(rms7,3)]}))\n",
    "            print(df_res)\n",
    "            main_df = main_df.append(df_res, ignore_index = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eperimentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columns = \"011\",\"101\",\"110\",\"111\",\"121\",\"112\",\"211\"\n",
    "df_res= pd.DataFrame(index=None, columns=columns)\n",
    "print(df_res)\n",
    "for i in range (0,20):\n",
    "            try:\n",
    "                matnr = high_frequency[i]\n",
    "                print(\"index : \",matnr)\n",
    "                output1,rms1,mae1 = ses(grp_mov,matnr,4,0.2)\n",
    "                output2,rms2,mae2 = ses(grp_mov,matnr,4,0.3)\n",
    "                output3,rms3,mae3 = ses(grp_mov,matnr,4,0.4)\n",
    "                output4,rms4,mae4 = ses(grp_mov,matnr,4,0.5)\n",
    "                output5,rms5,mae5 = ses(grp_mov,matnr,4,0.6)\n",
    "                output6,rms6,mae6 = ses(grp_mov,matnr,4,0.1)\n",
    "                output7,rms7,mae7 = ses(grp_mov,matnr,4,0.05)\n",
    "                df_res =pd.DataFrame(({\"matnr\" : [matnr],\n",
    "                    \"011\" : [round(rms1,3)],\n",
    "                    \"101\" : [round(rms2,3)],\n",
    "                   \"110\" : [round(rms3,3)],\n",
    "                   \"111\" : [round(rms4,3)],\n",
    "                   \"211\" : [round(rms5,3)],\n",
    "                   \"121\" : [round(rms6,3)],\n",
    "                   \"112\" : [round(rms7,3)]}))\n",
    "                print(df_res)\n",
    "                main_df = df_res.append(result_df, ignore_index = True) \n",
    "                print(main_df)\n",
    "\n",
    "#                 print(\"arima :\",rms)\n",
    "            except :\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
